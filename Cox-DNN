# Importing packages
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.regularizers import l1,l2
from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop, Nadam
from lifelines.utils import concordance_index

#Model setting
input_X = Input(shape=(x_tr.shape[1],))
layer_1 = Dense(32, activation='relu')(input_X)
layer_2 = Dense(16, activation='relu')(layer_1)
layer_2 = Dropout(0.1)(layer_2)   #droupout
layer_3 = Dense(8, activation='relu')(layer_2)
#layer_3 = Dense(8, activation='relu', kernel_regularizer='l2')(layer_2)
y_pred = Dense(1, activation='linear', use_bias=False)(layer_3) #output layer
y_true = Input(shape=(np.shape(y_tr)[1],), dtype='float32')
model1 = Model(inputs=[input_X,y_true], outputs=[y_pred])

model1.add_loss(lossB(y_true, y_pred)) # loss function: negative Breslow log-likelihood  
model1.compile(optimizer=Adam(learning_rate=0.002))
earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta = 0.001)
reducelr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.95, 
                                                verbose = 0, min_lr = 0)
# Model fitting
history = model1.fit([x_tr, y_tr], epochs=2000, batch_size=32, verbose=1, validation_split = 0.2, 
                    callbacks=[earlystop,reducelr])  
pred1 = model1.predict([x_te,y_te])
time=y_te[:,0]; status=y_te[:,1]
c_index_DNN=concordance_index(time, -pred1, event_observed=status) 
t= np.linspace(durations_test.min(), durations_test.max(), 100) #time_grid 
mu1_te=pred1
IBS_te_DNN = BS_cox(t=t,time=y_te[:,0],status=y_te[:,1],pred=mu1_te)['Integrated Brier Score'][0] 
